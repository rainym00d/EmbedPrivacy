{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process origin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load origin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_pro(texts):\n",
    "    text = \"\"\n",
    "    for t in texts:\n",
    "        text = text + t.strip('\\n') + ' '\n",
    "    return text.strip()\n",
    "\n",
    "data_name_list = ['train', 'val', 'test']\n",
    "\n",
    "data_dict = {\n",
    "    \"train\": [],\n",
    "    \"val\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "for data_name in data_name_list:\n",
    "    path = os.path.join('/data/ectsum', data_name)\n",
    "    path = os.path.join(path, 'gt_summaries')\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            texts = f.readlines()\n",
    "            data_dict[data_name].append(summary_pro(texts))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * We don't need to use spacy since the pattern is very simple.\n",
    "for data_name in data_name_list:\n",
    "    tmp = []\n",
    "    for para in data_dict[data_name]:\n",
    "        sentence_list = para.split('. ')\n",
    "        sentence_list = [s + \".\" for s in sentence_list[:-1]] + [sentence_list[-1]]\n",
    "        tmp += sentence_list\n",
    "    data_dict[data_name] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create huggingface datasets type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_dict({\"text\": data_dict[\"train\"]}),\n",
    "    \"valid\": datasets.Dataset.from_dict({\"text\": data_dict[\"val\"]}),\n",
    "    \"test\": datasets.Dataset.from_dict({\"text\": data_dict[\"test\"]}),\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_dataset = datasets.concatenate_datasets([dataset[\"train\"], dataset[\"valid\"], dataset[\"test\"]])\n",
    "\n",
    "union_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    }
   ],
   "source": [
    "union_dataset.save_to_disk(\"./tmp/ectsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get embedding & save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sup-simcse-bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=8 ../embedding/sup-simcse-bert-base-uncased.py \\\n",
    "    --input_dataset \"./tmp/ectsum\" \\\n",
    "    --output_dataset \"your_output_dir\" \\\n",
    "    --train_size 6981 \\\n",
    "    --valid_size 1009 \\\n",
    "    --test_size 2001 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e5-large-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=8 ../embedding/e5-large-v2.py \\\n",
    "    --input_dataset \"./tmp/ectsum\" \\\n",
    "    --output_dataset \"your_output_dir\" \\\n",
    "    --train_size 6981 \\\n",
    "    --valid_size 1009 \\\n",
    "    --test_size 2001 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bge-large-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=8 ../embedding/bge-large-en.py \\\n",
    "    --input_dataset \"./tmp/ectsum\" \\\n",
    "    --output_dataset \"your_output_dir\" \\\n",
    "    --train_size 6981 \\\n",
    "    --valid_size 1009 \\\n",
    "    --test_size 2001 \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
